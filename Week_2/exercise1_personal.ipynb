{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils \n",
    "\n",
    "# define the submission/grader object for this exercise\n",
    "grader = utils.Grader()\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Instructions: Return the 5x5 identity matrix  </h1>\n",
    "           <li>  In octave, we return values by defining which variables </li>\n",
    "           <li>  represent the return values (at the top of the file)</li>\n",
    "           <li>  and then set them accordingly. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmUpExercise():\n",
    "    identity_5 = np.identity(5)\n",
    "    display(identity_5)\n",
    "    return identity_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ======================= Part 2: Plotting =======================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('Data/ex1data1.txt',sep=',',header=None,names=[\"X\",\"y\"])\n",
    "data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.59200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.13020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.66200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.85400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.82330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8707</td>\n",
       "      <td>7.20290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.3054</td>\n",
       "      <td>1.98690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8.2934</td>\n",
       "      <td>0.14454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13.3940</td>\n",
       "      <td>9.05510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.4369</td>\n",
       "      <td>0.61705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         y\n",
       "0    6.1101  17.59200\n",
       "1    5.5277   9.13020\n",
       "2    8.5186  13.66200\n",
       "3    7.0032  11.85400\n",
       "4    5.8598   6.82330\n",
       "..      ...       ...\n",
       "92   5.8707   7.20290\n",
       "93   5.3054   1.98690\n",
       "94   8.2934   0.14454\n",
       "95  13.3940   9.05510\n",
       "96   5.4369   0.61705\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data[\"X\"]\n",
    "y= data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are the CEO of a\n",
    "restaurant franchise and are considering different cities for opening a new\n",
    "outlet. The chain already has trucks in various cities and you have data for\n",
    "profits and populations from the cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 2.2 Gradient Descent\n",
    "\n",
    "In this part, you will fit the linear regression parameters $\\theta$ to our dataset using gradient descent.\n",
    "\n",
    "#### 2.2.1 Update Equations\n",
    "\n",
    "The objective of linear regression is to minimize the cost function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_{\\theta}(x^{(i)}) - y^{(i)}\\right)^2$$\n",
    "\n",
    "where the hypothesis $h_\\theta(x)$ is given by the linear model\n",
    "$$ h_\\theta(x) = \\theta^Tx = \\theta_0 + \\theta_1 x_1$$\n",
    "\n",
    "Recall that the parameters of your model are the $\\theta_j$ values. These are\n",
    "the values you will adjust to minimize cost $J(\\theta)$. One way to do this is to\n",
    "use the batch gradient descent algorithm. In batch gradient descent, each\n",
    "iteration performs the update\n",
    "\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{simultaneously update } \\theta_j \\text{ for all } j$$\n",
    "\n",
    "With each step of gradient descent, your parameters $\\theta_j$ come closer to the optimal values that will achieve the lowest cost J($\\theta$).\n",
    "\n",
    "\n",
    "**Implementation Note:** We store each example as a row in the the $X$ matrix in Python `numpy`. To take into account the intercept term  $\\theta_0$, we add an additional first column to $X$ and set it to all ones. This allows us to treat $\\theta_0$ as simply another 'feature'.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 2.2.2 Implementation\n",
    "\n",
    "We have already set up the data for linear regression. In the following cell, we add another dimension to our data to accommodate the $ \\theta_0 $ intercept term. Do NOT execute this cell more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    0\n",
       "y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() # No missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.159800</td>\n",
       "      <td>5.839135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.869884</td>\n",
       "      <td>5.510262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.026900</td>\n",
       "      <td>-2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.707700</td>\n",
       "      <td>1.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.589400</td>\n",
       "      <td>4.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.578100</td>\n",
       "      <td>7.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.203000</td>\n",
       "      <td>24.147000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X          y\n",
       "count  97.000000  97.000000\n",
       "mean    8.159800   5.839135\n",
       "std     3.869884   5.510262\n",
       "min     5.026900  -2.680700\n",
       "25%     5.707700   1.986900\n",
       "50%     6.589400   4.562300\n",
       "75%     8.578100   7.046700\n",
       "max    22.203000  24.147000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"X\"].values\n",
    "\n",
    "y = data[\"y\"].values\n",
    "\n",
    "m= len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm\n",
    "\n",
    "- Repeat until convergence is reached\n",
    "$$ \\theta_i := \\theta_{old} - \\alpha \\frac{dy}{d\\theta} L(\\theta_i,Y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros([2,1])\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "def PrepareX(X):\n",
    "    X = X[:,np.newaxis]\n",
    "    ones = np.ones((m,1))\n",
    "    X = np.hstack((ones, X)) # adding the intercept term\n",
    "    return X\n",
    "\n",
    "    \n",
    "def PrepareY(y):\n",
    "    return y[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=PrepareX(X)\n",
    "train_Y=PrepareY(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the gradient descent algorithm\n",
    "\n",
    "def computeCost(X, y, theta):\n",
    "    temp = np.dot(X, theta) - y\n",
    "    J= np.sum(np.power(temp, 2)) / (2*m)\n",
    "    \n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([np.ones(m), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.072733877455676"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = computeCost(train_X,y, theta=np.zeros(2))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[-1],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With theta = [0, 0] Cost computed  32.072733877455676\n",
      "Expected cost value (approximately) 32.07\n",
      "\n",
      "With theta = [-1, 2] Cost computed  54.24245508201238\n",
      "Expected cost value (approximately) 54.24\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(train_X, train_Y, theta=np.zeros([2,1]))\n",
    "\n",
    "\n",
    "print('With theta = [0, 0] Cost computed ', J)\n",
    "print('Expected cost value (approximately) 32.07\\n')\n",
    "\n",
    "# further testing of the cost function\n",
    "J = computeCost(train_X, train_Y, theta=np.array([[-1],[2]]))\n",
    "\n",
    "\n",
    "print('With theta = [-1, 2] Cost computed ' , J)\n",
    "print('Expected cost value (approximately) 54.24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise linear-regression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "                           Normal Equations |  10 /  10 | Nice work!\n",
      "                           Warm up exercise |   0 /  40 | Your answer is incorrect.\n",
      "          Computing Cost (for one variable) |   0 /  50 | Your answer is incorrect.\n",
      "        Gradient Descent (for one variable) |   0 /   0 | Your answer is incorrect.\n",
      "                      Feature Normalization |   0 /   0 | Your answer is incorrect.\n",
      "    Computing Cost (for multiple variables) |   0 /   0 | Your answer is incorrect.\n",
      "  Gradient Descent (for multiple variables) |   0 /   0 | Your answer is incorrect.\n",
      "                                  --------------------------------\n",
      "                                            |  10 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[2] = computeCost\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.072733877455676\n"
     ]
    }
   ],
   "source": [
    "Original_cost = computeCost(train_X, train_Y, theta)\n",
    "print(Original_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.computeCost(X, y, theta)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise linear-regression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid email or token. You used an invalid email or your token may have expired. Please make sure you have entered all fields correctly. Try generating a new token if the issue still persists.\n"
     ]
    }
   ],
   "source": [
    "# Grading of question 1 \n",
    "grader = utils.Grader()\n",
    "\n",
    "grader[1] = warmUpExercise\n",
    "grader.grade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.63029144]\n",
      " [ 1.16636235]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def hypothesis(X,theta):\n",
    "    return np.dot(X, theta)\n",
    "\n",
    "\n",
    "# epoch == one forward pass and one backward pass of all the training examples\n",
    "def LinReg_gradientDescent(X,y,theta,alpha,epoch):\n",
    "    for _ in range(epoch):\n",
    "        temp = hypothesis(X,theta) - y\n",
    "        temp = np.dot(X.T, temp)\n",
    "        theta = theta - (alpha/m) * temp\n",
    "        #Draw graph\n",
    "        # if( _  % 300 == 0):\n",
    "        #     DrawGraph(train_X,train_Y,theta)\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "\n",
    "def DrawGraph(train_X,train_Y,theta):\n",
    "    plt.scatter(train_X[:,1], train_Y)\n",
    "    plt.xlabel('Population of City in 10,000s')\n",
    "    plt.ylabel('Profit in $10,000s')\n",
    "    plt.plot(train_X[:,1], np.dot(train_X, theta),color=\"#FFDD44\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "theta = LinReg_gradientDescent(train_X,train_Y, theta, alpha, iterations)\n",
    "print(theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For population = 35,000, we predict a profit of  [4519.7678677]\n",
      "For population = 70,000, we predict a profit of  [45342.45012945]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict values for population sizes of 35,000 and 70,000\n",
    "predict1 = np.dot([1, 3.5], theta)\n",
    "print('For population = 35,000, we predict a profit of ',predict1*10000)\n",
    "\n",
    "predict2 = np.dot([1, 7], theta)\n",
    "print('For population = 70,000, we predict a profit of ',predict2*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting Solutions | Programming Exercise linear-regression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Part Name |     Score | Feedback\n",
      "                                  --------- |     ----- | --------\n",
      "                           Normal Equations |  10 /  10 | Nice work!\n",
      "                           Warm up exercise |   0 /  40 | Your answer is incorrect.\n",
      "          Computing Cost (for one variable) |   0 /  50 | Your answer is incorrect.\n",
      "        Gradient Descent (for one variable) |   0 /   0 | Your answer is incorrect.\n",
      "                      Feature Normalization |   0 /   0 | Your answer is incorrect.\n",
      "    Computing Cost (for multiple variables) |   0 /   0 | Your answer is incorrect.\n",
      "  Gradient Descent (for multiple variables) |   0 /   0 | Your answer is incorrect.\n",
      "                                  --------------------------------\n",
      "                                            |  10 / 100 |  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grader[2] = computeCost\n",
    "grader.grade()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.483388256587726\n"
     ]
    }
   ],
   "source": [
    "J = computeCost(train_X, train_Y, theta)\n",
    "print(J)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating theta and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_X[:,1], train_Y)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.plot(train_X[:,1], np.dot(train_X, theta))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with multiple variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_feet^2</th>\n",
       "      <th>number_bedrooms</th>\n",
       "      <th>price_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104</td>\n",
       "      <td>3</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1534</td>\n",
       "      <td>3</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "      <td>198999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1380</td>\n",
       "      <td>3</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1494</td>\n",
       "      <td>3</td>\n",
       "      <td>242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1940</td>\n",
       "      <td>4</td>\n",
       "      <td>239999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1890</td>\n",
       "      <td>3</td>\n",
       "      <td>329999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4478</td>\n",
       "      <td>5</td>\n",
       "      <td>699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1268</td>\n",
       "      <td>3</td>\n",
       "      <td>259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2300</td>\n",
       "      <td>4</td>\n",
       "      <td>449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1320</td>\n",
       "      <td>2</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1236</td>\n",
       "      <td>3</td>\n",
       "      <td>199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2609</td>\n",
       "      <td>4</td>\n",
       "      <td>499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3031</td>\n",
       "      <td>4</td>\n",
       "      <td>599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1767</td>\n",
       "      <td>3</td>\n",
       "      <td>252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1888</td>\n",
       "      <td>2</td>\n",
       "      <td>255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1604</td>\n",
       "      <td>3</td>\n",
       "      <td>242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1962</td>\n",
       "      <td>4</td>\n",
       "      <td>259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3890</td>\n",
       "      <td>3</td>\n",
       "      <td>573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1458</td>\n",
       "      <td>3</td>\n",
       "      <td>464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2526</td>\n",
       "      <td>3</td>\n",
       "      <td>469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2200</td>\n",
       "      <td>3</td>\n",
       "      <td>475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2637</td>\n",
       "      <td>3</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1839</td>\n",
       "      <td>2</td>\n",
       "      <td>349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2040</td>\n",
       "      <td>4</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3137</td>\n",
       "      <td>3</td>\n",
       "      <td>579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1811</td>\n",
       "      <td>4</td>\n",
       "      <td>285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1239</td>\n",
       "      <td>3</td>\n",
       "      <td>229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2132</td>\n",
       "      <td>4</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4215</td>\n",
       "      <td>4</td>\n",
       "      <td>549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2162</td>\n",
       "      <td>4</td>\n",
       "      <td>287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1664</td>\n",
       "      <td>2</td>\n",
       "      <td>368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2238</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2567</td>\n",
       "      <td>4</td>\n",
       "      <td>314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>852</td>\n",
       "      <td>2</td>\n",
       "      <td>179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1852</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1203</td>\n",
       "      <td>3</td>\n",
       "      <td>239500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    size_feet^2  number_bedrooms  price_house\n",
       "0          2104                3       399900\n",
       "1          1600                3       329900\n",
       "2          2400                3       369000\n",
       "3          1416                2       232000\n",
       "4          3000                4       539900\n",
       "5          1985                4       299900\n",
       "6          1534                3       314900\n",
       "7          1427                3       198999\n",
       "8          1380                3       212000\n",
       "9          1494                3       242500\n",
       "10         1940                4       239999\n",
       "11         2000                3       347000\n",
       "12         1890                3       329999\n",
       "13         4478                5       699900\n",
       "14         1268                3       259900\n",
       "15         2300                4       449900\n",
       "16         1320                2       299900\n",
       "17         1236                3       199900\n",
       "18         2609                4       499998\n",
       "19         3031                4       599000\n",
       "20         1767                3       252900\n",
       "21         1888                2       255000\n",
       "22         1604                3       242900\n",
       "23         1962                4       259900\n",
       "24         3890                3       573900\n",
       "25         1100                3       249900\n",
       "26         1458                3       464500\n",
       "27         2526                3       469000\n",
       "28         2200                3       475000\n",
       "29         2637                3       299900\n",
       "30         1839                2       349900\n",
       "31         1000                1       169900\n",
       "32         2040                4       314900\n",
       "33         3137                3       579900\n",
       "34         1811                4       285900\n",
       "35         1437                3       249900\n",
       "36         1239                3       229900\n",
       "37         2132                4       345000\n",
       "38         4215                4       549000\n",
       "39         2162                4       287000\n",
       "40         1664                2       368500\n",
       "41         2238                3       329900\n",
       "42         2567                4       314000\n",
       "43         1200                3       299000\n",
       "44          852                2       179900\n",
       "45         1852                4       299900\n",
       "46         1203                3       239500"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = pd.read_csv('Data/ex1data2.txt', sep = ',', header = None,names=['size_feet^2','number_bedrooms','price_house'])\n",
    "\n",
    "\n",
    "data_2 = pd.DataFrame(data_2)\n",
    "\n",
    "X = data_2.iloc[:,0:2] # read first two columns into X\n",
    "y = data_2.iloc[:,2] # read the third column into y\n",
    "\n",
    "m = len(y) # no. of training samples\n",
    "\n",
    "data_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing feature Normalization\n",
    "\n",
    "- Substract the mean value of each feature from the data set \n",
    "- After subtracting the mean, additionally scale (divide) the feature values\n",
    "by their respective \"standard deviations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ( X - X.mean())/np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10257/2162591772.py:6: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:,np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((m,1))\n",
    "X = np.hstack((ones, X))\n",
    "alpha = 0.01\n",
    "num_iters = 400\n",
    "theta = np.zeros((3,1))\n",
    "y = y[:,np.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65591548106.45744\n"
     ]
    }
   ],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    temp = np.dot(X, theta) - y\n",
    "    return np.sum(np.power(temp, 2)) / (2*m)\n",
    "J = computeCostMulti(X, y, theta)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334302.06399328]\n",
      " [ 99411.44947359]\n",
      " [  3267.01285407]]\n"
     ]
    }
   ],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    for _ in range(iterations):\n",
    "        temp = np.dot(X, theta) - y\n",
    "        temp = np.dot(X.T, temp)\n",
    "        theta = theta - (alpha/m) * temp\n",
    "    return theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "theta = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2105448288.6292474\n"
     ]
    }
   ],
   "source": [
    "J = computeCostMulti(X, y, theta)\n",
    "print(J)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "468f25ad0239460415b7e6b7483d5c8f7213894121f6fb96c4cb6ef93fffe534"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
